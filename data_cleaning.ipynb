{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Processing Notebook\n",
    "### This notebook goes through loading, cleaning and organising of the data ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python 3.11, Conda environment.\n",
    "# Ensure using env.yml to create the environment (data_analysis_env). \n",
    "# Importing data analysis & visualisation librarys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Initial exploration of the data to gain understanding and inform cleaning/processing. \n",
    "###         ---- **CHECK THE DATA PATHS ARE CORRECT FOR YOUR LOCAL ENV** ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into DataFrames.\n",
    "# Please adjust paths accordingly from Drive link provided, do not download locally. \n",
    "spec_data_path = \"../data/raw_data/order_specifications_csv.csv\"\n",
    "sched_data_path = \"../data/raw_data/order_schedules_csv.csv\"\n",
    "spec_df = pd.read_csv(spec_data_path)\n",
    "sched_df = pd.read_csv(sched_data_path)\n",
    "\n",
    "# Strip the id column for it to be used as index and merging later on.\n",
    "spec_df['id'] = spec_df['id'].str.strip()\n",
    "sched_df['id'] = sched_df['id'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" There are {len(sched_df['product'].unique())} unique schedules in the data\")\n",
    "print(f\" There are {sched_df['id'].nunique()} unique job numbers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"The Schedule data looks like: \n",
    "      \n",
    "{sched_df.head()}\n",
    "\n",
    "...And the spec data looks like: \n",
    "\n",
    "{spec_df.head()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Data shape manipulation: Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary columns\n",
    "spec_df = spec_df.drop(columns=['type', 'spec_id'])\n",
    "\n",
    "# Pivot the spec df so each job number is its own row and then ensure the index is a String object\n",
    "wide_spec_df = spec_df.pivot(index='id', columns='question_no', values='answer')\n",
    "wide_spec_df.index = wide_spec_df.index.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Data shape manipulation: Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary columns\n",
    "sched_df = sched_df.drop(columns=['x', 'y', 'z', 'a', 'b'])\n",
    "sched_df = sched_df.dropna()\n",
    "\n",
    "# Create a multi-hot encoding of the schedules so each possible schedule code has its own binary identifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "schedule_codes = sched_df.groupby('id')['x'].apply(list) # Create a df with a list of schedules for each job\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "wide_sched_df = pd.DataFrame(mlb.fit_transform(schedule_codes), index=schedule_codes.index, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Merging both tables together on jobno (ID) & Aligning seperate DataFrames\n",
    "\n",
    "There will be aligned_spec_df & aligned_sched_df dataframes that contain the spec data, aligned, shaped and pivoted. While also having a merged_df, merged dataframe of both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_spec_df = wide_spec_df.sort_index()\n",
    "wide_sched_df = wide_sched_df.sort_index()\n",
    "\n",
    "# Finding commmon ID's and creating aligned tables.\n",
    "intersecting_jobs = wide_spec_df.index.intersection(wide_sched_df.index)\n",
    "\n",
    "# Creating two seperate, aligned, tables for training.\n",
    "aligned_spec_df = wide_spec_df[wide_spec_df.index.isin(intersecting_jobs)]\n",
    "aligned_sched_df = wide_sched_df[wide_sched_df.index.isin(intersecting_jobs)]\n",
    "\n",
    "# Strip whitespace from columns for cleaning in future\n",
    "aligned_sched_df.columns = aligned_sched_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_spec_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_sched_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Initial EDA & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How common is each schedule? \n",
    "schedule_count = aligned_sched_df.sum().sort_values(ascending=True)\n",
    "schedule_count.plot(kind='bar', figsize=(15,5))\n",
    "plt.title('Schedule frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Order count')\n",
    "plt.xlabel('Schedule')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The above tells us that there are many orders that contain schedule codes unrelated to Insole manufacturing specifications. These are likely insole orders where there has also been another, seperate, product combined/added onto the order. Thus, we need to remove these other product codes from the data as they are irrelevant. For example, a BAPT3 is a Body Armour Pro-Term boot - not related to insoles. \n",
    "Two schedule codes appear really commonly, EZI-RIZE-MALE and EZI-RIZE-FEMALE, these are sepeart heel lift products, also not relevant to Insole manufacture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all schedule columns that are unrelated to insole manufacture\n",
    "insole_schedule_list = ['B36', 'B41', 'B43', 'B54A', 'B54B', 'B54C', 'B55A', 'B55B', 'B56']\n",
    "aligned_sched_df = aligned_sched_df[insole_schedule_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-generate visualisation after cleaning. \n",
    "schedule_count = aligned_sched_df.sum().sort_values(ascending=True)\n",
    "schedule_count.plot(kind='bar', figsize=(15,5))\n",
    "plt.title('Schedule frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Order count')\n",
    "plt.xlabel('Schedule')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The above shows that there is high cardinality among the schedules. This will need to be considered in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER CLEANING, Creating a merged table for convenience\n",
    "merged_df = aligned_spec_df.join(aligned_sched_df, how='inner')\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting free text columns in the merged dataframe for encoding in model training\n",
    "free_text_cols = [18,20,22,24,27,30,52,62,64,66,68,71,74,96]\n",
    "merged_df = merged_df.drop(columns=[18,20,22,24,27,30,52,62,64,66,68,71,74,96])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Exporting cleaned dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../data/processed/merged_data_base.csv', index=True)\n",
    "aligned_sched_df.to_csv('../data/processed/clean_schedule_base.csv', index=True)\n",
    "aligned_spec_df.to_csv('../data/processed/clean_specification_base.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
