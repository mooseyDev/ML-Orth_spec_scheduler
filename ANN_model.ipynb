{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Artifiical Neural network training notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Although the raw data has now been cleaned, each AI/ML Model we train needs to first process the data so it is formatted slightly differently. \n",
    "For Random Forest models, we need to impute missing numerical values with a neutral constant like -1 and for catagorical features we need to impute with a neutral catagory like \"missing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must pip install tensorflow in Conda environment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in csv, create df and drop the index row, not needed for training\n",
    "csvpath = '../data/processed/merged_data_base.csv'\n",
    "df = pd.read_csv(csvpath)\n",
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out columns as labels and columns that are features, create new X and Y for training\n",
    "label_cols = ['B36', 'B41', 'B43', 'B54A', 'B54B', 'B54C', 'B55A', 'B55B', 'B56'] # create array with all labels\n",
    "features = [col for col in df.columns if col not in label_cols] # get all columns that arent in the label column array\n",
    "\n",
    "Y = df[label_cols].copy() # Y df becomes labels \n",
    "X = df[features].copy() # X df becomes the features\n",
    "\n",
    "# now identify which columns are catagorical and which are numerical\n",
    "ordinal_cols = X.select_dtypes(include='object').columns.to_list() # Get all columns that are object dtype\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.to_list() # Get all cols that are num dytpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputing\n",
    "X[num_cols] = X[num_cols].fillna(-1) # change num NaN's to -1\n",
    "X[ordinal_cols] = X[ordinal_cols].fillna('missing') # Change catagory NaN's to 'missing'\n",
    "\n",
    "# One-Hot encode catagorical columns using get_dummies()\n",
    "X = pd.get_dummies(X, columns=ordinal_cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test and training splits\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN configuration, 3 dense layers using relu and sigmoid output layer, 9 labels so 9 nodes.\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(9, activation='sigmoid') # Tried softmax and sigmoid, sigmoid was superior by 0.8\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model for training\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), # arbitrary learning optimiser\n",
    "              loss='binary_crossentropy', # binary due to MLC task context\n",
    "              metrics=[AUC(name=\"AUC\")]) #AUC chosen due to MLC context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_scaled, Y_test, verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_prediciton = model.predict(X_test_scaled)\n",
    "y_prediciton_binary = (y_prediciton > 0.5).astype(int)\n",
    "print(classification_report(Y_test, y_prediciton_binary, target_names=label_cols, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Model Accuracy Eval.:  \n",
    "AUC: 0.996\n",
    "Average F1-Score: 0.99\n",
    "Lowest precision = 0.98 on B41\n",
    "Lowest Recall = 0.7 on B55B\n",
    "Lowest F-1 = 0.82 on B55B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Model Inference Eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model.predict(X_test_scaled[:10])\n",
    "inf_time = (time.time() - start_time) /10\n",
    "print(inf_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss # fraction of labesl incorrectly classified.\n",
    "print(hamming_loss(Y_test, y_prediciton_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # EXACT match ration == Accuracy %\n",
    "print(accuracy_score(Y_test, y_prediciton_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "conf = multilabel_confusion_matrix(Y_test, y_prediciton_binary)\n",
    "\n",
    "labels = ['B36', 'B41', 'B43', 'B54A', 'B54B', 'B54C', 'B55A', 'B55B', 'B56']\n",
    "\n",
    "for i, mtx in enumerate(conf):\n",
    "    plt.figure()\n",
    "    sns.heatmap(mtx, annot=True, fmt='d', cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"confusion matrix for {labels[i]}\")\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
